{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#v1\n",
    "\n",
    "# resnet18_training.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Paths\n",
    "DATASET_DIR = \"../data/processed\"\n",
    "train_dir = os.path.join(DATASET_DIR, \"train\")\n",
    "val_dir = os.path.join(DATASET_DIR, \"val\")\n",
    "test_dir = os.path.join(DATASET_DIR, \"test\")\n",
    "# Transforms for ResNet18\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Load datasets\n",
    "datasets_dict = {\n",
    "    'train': datasets.ImageFolder(train_dir, transform=transform),\n",
    "    'val': datasets.ImageFolder(val_dir, transform=transform),\n",
    "    'test': datasets.ImageFolder(test_dir, transform=transform)\n",
    "}\n",
    "# DataLoaders\n",
    "dataloaders = {\n",
    "    x: DataLoader(datasets_dict[x], batch_size=32, shuffle=(x == 'train'), num_workers=2)\n",
    "    for x in ['train', 'val', 'test']\n",
    "}\n",
    "\n",
    "class_names = datasets_dict['train'].classes\n",
    "num_classes = len(class_names)\n",
    "# === NEW: Compute class weights ===\n",
    "train_labels = [label for _, label in datasets_dict['train']]\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.arange(num_classes), y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "# Load pretrained ResNet18 and modify final layer\n",
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "# Use weighted loss\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=\"runs/resnet18_experiment\")\n",
    "# Training loop\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n",
    "    best_val_loss = float('inf')\n",
    "    train_loss_hist, val_loss_hist = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
    "                for inputs, labels in tepoch:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(datasets_dict[phase])\n",
    "            epoch_acc = running_corrects.double() / len(datasets_dict[phase])\n",
    "\n",
    "            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            writer.add_scalar(f\"Loss/{phase}\", epoch_loss, epoch)\n",
    "            writer.add_scalar(f\"Accuracy/{phase}\", epoch_acc, epoch)\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss_hist.append(epoch_loss)\n",
    "            else:\n",
    "                val_loss_hist.append(epoch_loss)\n",
    "                if epoch_loss < best_val_loss:\n",
    "                    best_val_loss = epoch_loss\n",
    "                    torch.save(model.state_dict(), \"../model/best_resnet18_model.pth\")\n",
    "\n",
    "    print(\"\\nTraining complete. Best validation loss: {:.4f}\".format(best_val_loss))\n",
    "    return train_loss_hist, val_loss_hist\n",
    "# Train\n",
    "train_loss_hist, val_loss_hist = train_model(model, dataloaders, criterion, optimizer, num_epochs=10)\n",
    "# Evaluation\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "    print(f\"\\nTest Accuracy: {100 * correct / total:.2f}%\")\n",
    "evaluate_model(model, dataloaders[\"test\"])\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss_hist, label=\"Train Loss\")\n",
    "plt.plot(val_loss_hist, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss_curve.png\")\n",
    "plt.show()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# v2\n",
    "# resnet18_training.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Paths\n",
    "DATASET_DIR = \"../data/processed\"\n",
    "train_dir = os.path.join(DATASET_DIR, \"train\")\n",
    "val_dir = os.path.join(DATASET_DIR, \"val\")\n",
    "test_dir = os.path.join(DATASET_DIR, \"test\")\n",
    "# Transforms for ResNet18\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Load datasets\n",
    "datasets_dict = {\n",
    "    'train': datasets.ImageFolder(train_dir, transform=transform),\n",
    "    'val': datasets.ImageFolder(val_dir, transform=transform),\n",
    "    'test': datasets.ImageFolder(test_dir, transform=transform)\n",
    "}\n",
    "# DataLoaders\n",
    "dataloaders = {\n",
    "    x: DataLoader(datasets_dict[x], batch_size=32, shuffle=(x == 'train'), num_workers=4, prefetch_factor=4)\n",
    "    for x in ['train', 'val', 'test']\n",
    "}\n",
    "\n",
    "class_names = datasets_dict['train'].classes\n",
    "num_classes = len(class_names)\n",
    "# === NEW: Compute class weights ===\n",
    "train_labels = [label for _, label in datasets_dict['train']]\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.arange(num_classes), y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "# Load pretrained ResNet18 and modify final layer\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "# todo take this out later\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False  # Freeze all layers\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "# Use weighted loss\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "# Get trainable parameters only\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(trainable_params, lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=\"runs/resnet18_experiment_2\")\n",
    "# Training loop\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n",
    "    best_val_loss = float('inf')\n",
    "    train_loss_hist, val_loss_hist = [], []\n",
    "    train_acc_hist, val_acc_hist = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
    "                for i, (inputs, labels) in enumerate(tepoch):\n",
    "                    # Optional: show batch progress every 10 batches\n",
    "                    # if i % 10 == 0:  # 🔍 Debug: monitor training progress\n",
    "                    #     print(f\"[{phase.upper()}] Epoch {epoch+1} - Batch {i+1}/{len(dataloaders[phase])}\")  # REMOVE LATER\n",
    "\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(datasets_dict[phase])\n",
    "            epoch_acc = running_corrects.double() / len(datasets_dict[phase])\n",
    "\n",
    "            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            writer.add_scalar(f\"Loss/{phase}\", epoch_loss, epoch)\n",
    "            writer.add_scalar(f\"Accuracy/{phase}\", epoch_acc, epoch)\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss_hist.append(epoch_loss)\n",
    "                train_acc_hist.append(epoch_acc.item())\n",
    "            else:\n",
    "                val_loss_hist.append(epoch_loss)\n",
    "                val_acc_hist.append(epoch_acc.item())\n",
    "                scheduler.step(epoch_loss)\n",
    "\n",
    "                if epoch_loss < best_val_loss:\n",
    "                    best_val_loss = epoch_loss\n",
    "                    torch.save(model.state_dict(), \"../model/dermai_model.pth\")\n",
    "\n",
    "    print(\"\\nTraining complete. Best validation loss: {:.4f}\".format(best_val_loss))\n",
    "    return train_loss_hist, val_loss_hist, train_acc_hist, val_acc_hist\n",
    "# Train\n",
    "train_loss_hist, val_loss_hist, train_acc_hist, val_acc_hist = train_model(model, dataloaders, criterion, optimizer, num_epochs=10)\n",
    "# Save complete model for inference\n",
    "complete_model_path = \"../model/dermai_model.pt\"\n",
    "torch.save(model, complete_model_path)\n",
    "print(f\"\\nFinal model saved to {complete_model_path}\")\n",
    "# Evaluation\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "    print(f\"\\nTest Accuracy: {100 * correct / total:.2f}%\")\n",
    "evaluate_model(model, dataloaders[\"test\"])\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_loss_hist) + 1), train_loss_hist,label=\"Training Loss\")\n",
    "plt.plot(range(1, len(val_loss_hist) + 1), val_loss_hist,label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss_curve.png\")\n",
    "plt.show()\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_acc_hist) + 1), train_acc_hist,label=\"Training Accuracy\")\n",
    "plt.plot(range(1, len(val_acc_hist) + 1), val_acc_hist,label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"accuracy_curve.png\")\n",
    "plt.show()\n",
    "\n",
    "writer.close()"
   ],
   "id": "15b0a3d38f043f1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#v3\n",
    "\n",
    "# resnet18_training.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Paths\n",
    "DATASET_DIR = \"../data/processed\"\n",
    "train_dir = os.path.join(DATASET_DIR, \"train\")\n",
    "val_dir = os.path.join(DATASET_DIR, \"val\")\n",
    "test_dir = os.path.join(DATASET_DIR, \"test\")\n",
    "# === Transforms ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Load datasets\n",
    "datasets_dict = {\n",
    "    'train': datasets.ImageFolder(train_dir, transform=transform),\n",
    "    'val': datasets.ImageFolder(val_dir, transform=transform),\n",
    "    'test': datasets.ImageFolder(test_dir, transform=transform)\n",
    "}\n",
    "# DataLoaders\n",
    "dataloaders = {\n",
    "    x: DataLoader(datasets_dict[x], batch_size=32, shuffle=(x == 'train'), num_workers=4, prefetch_factor=4)\n",
    "    for x in ['train', 'val', 'test']\n",
    "}\n",
    "\n",
    "class_names = datasets_dict['train'].classes\n",
    "num_classes = len(class_names)\n",
    "# === NEW: Compute class weights ===\n",
    "train_labels = [label for _, label in datasets_dict['train']]\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.arange(num_classes), y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "# === Load and Modify Pretrained Model ===\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# ✅ Unfreeze layer3 + layer4 + fc\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "# ✅ Weighted Loss + Label Smoothing\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)\n",
    "\n",
    "# ✅ Add weight decay (L2 regularization)\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(trainable_params, lr=0.001, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=\"runs/resnet18_experiment_v3\")\n",
    "# === Training Function with Early Stopping ===\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=20, patience=3):\n",
    "    best_val_loss = float('inf')\n",
    "    train_loss_hist, val_loss_hist = [], []\n",
    "    train_acc_hist, val_acc_hist = [], []\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "            running_loss, running_corrects = 0.0, 0\n",
    "\n",
    "            with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
    "                for inputs, labels in tepoch:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(datasets_dict[phase])\n",
    "            epoch_acc = running_corrects.double() / len(datasets_dict[phase])\n",
    "\n",
    "            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "            writer.add_scalar(f\"Loss/{phase}\", epoch_loss, epoch)\n",
    "            writer.add_scalar(f\"Accuracy/{phase}\", epoch_acc, epoch)\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss_hist.append(epoch_loss)\n",
    "                train_acc_hist.append(epoch_acc.item())\n",
    "            else:\n",
    "                val_loss_hist.append(epoch_loss)\n",
    "                val_acc_hist.append(epoch_acc.item())\n",
    "                scheduler.step(epoch_loss)\n",
    "\n",
    "                if epoch_loss < best_val_loss:\n",
    "                    best_val_loss = epoch_loss\n",
    "                    torch.save(model.state_dict(), \"../model/dermai_model_v2.pth\")\n",
    "                    patience_counter = 0  # Reset patience if improved\n",
    "                    print(\"✅ Best model updated.\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    print(f\"⚠️ Patience: {patience_counter}/{patience}\")\n",
    "                    if patience_counter >= patience:\n",
    "                        print(\"⏹️ Early stopping triggered.\")\n",
    "                        return train_loss_hist, val_loss_hist, train_acc_hist, val_acc_hist\n",
    "\n",
    "    print(\"\\n✅ Training complete. Best validation loss: {:.4f}\".format(best_val_loss))\n",
    "    return train_loss_hist, val_loss_hist, train_acc_hist, val_acc_hist\n",
    "# === Train ===\n",
    "train_loss_hist, val_loss_hist, train_acc_hist, val_acc_hist = train_model(\n",
    "    model, dataloaders, criterion, optimizer, num_epochs=20, patience=5\n",
    ")\n",
    "# Save full model\n",
    "complete_model_path = \"../model/dermai_model_v2.pt\"\n",
    "torch.save(model, complete_model_path)\n",
    "print(f\"\\n📦 Final model saved to {complete_model_path}\")\n",
    "# === Evaluation ===\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "    print(f\"\\n🧪 Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "evaluate_model(model, dataloaders[\"test\"])\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_loss_hist) + 1), train_loss_hist,label=\"Training Loss\")\n",
    "plt.plot(range(1, len(val_loss_hist) + 1), val_loss_hist,label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss_curve_v2.png\")\n",
    "plt.show()\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_acc_hist) + 1), train_acc_hist,label=\"Training Accuracy\")\n",
    "plt.plot(range(1, len(val_acc_hist) + 1), val_acc_hist,label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"accuracy_curve_v2.png\")\n",
    "plt.show()\n",
    "\n",
    "writer.close()"
   ],
   "id": "9b0c50d81b816809"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
