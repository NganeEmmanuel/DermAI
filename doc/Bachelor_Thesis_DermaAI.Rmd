---
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    latex_engine: xelatex
    keep_tex: true
    includes:
      in_header: preamble.tex
      before_body: titlepage.tex
  word_document:
    reference_docx: apa-styled.docx
fontsize: 12pt
mainfont: Times New Roman
linkcolor: black
colorlinks: false
linestretch: 1.5
classoption: oneside
geometry: margin=1in

# --- Referencing ---
bibliography: references.bib    # Your BibTeX file
csl: apa.csl                     # APA citation style file
link-citations: true             # Makes citations clickable
---


<!-- ### Preliminary Pages

* **Declaration**
* **Certification**
* **Dedication**
* **Acknowledgments**
* **Faculty Approval**
* **Abstract**
* **Keywords**
* **Table of Contents**
* **List of Tables**
* **List of Figures**
* **List of Acronyms and Abbreviations**

--->

\newpage

```{=tex}
\listoffigures
\newpage
```

\newpage

# Chapter 1: Introduction
## Introduction

Skin lesions encompass a broad spectrum of abnormalities in the skin, ranging from benign conditions such as moles and warts to malignant manifestations like melanoma and squamous cell carcinoma. Globally, these dermatological disorders present a significant public health challenge, with skin cancers alone accounting for millions of new cases annually and exerting substantial socioeconomic and healthcare burdens [@ogudo2023optimal], [@kassem2021machine]. The prevalence of skin lesions has been amplified by factors such as increased ultraviolet (UV) exposure due to climate change, demographic transitions, and lifestyle changes, contributing to both malignant and non-malignant skin disorders [@zafar2023skin].

In high-income countries, early diagnosis is often facilitated by access to trained dermatologists, advanced imaging technologies, and well-established referral systems. However, in low- and middle-income countries (LMICs), particularly in sub-Saharan Africa, dermatology services remain sparse, with a severe shortage of qualified dermatologists and specialized diagnostic tools [@hay2006skin]. This disparity often leads to delayed diagnoses, inappropriate treatments, and preventable morbidity and mortality from conditions that are otherwise treatable when detected early.

Cameroon, like many African nations, faces a dual challenge: the burden of infectious skin diseases such as fungal infections, scabies, and bacterial dermatitis coexists with a growing incidence of non-communicable skin disorders, including actinic keratosis, psoriasis, and malignant lesions [@van2005common]. The limited integration of dermatological screening into primary healthcare, coupled with the absence of large-scale public awareness campaigns, exacerbates the problem.

Recent advancements in artificial intelligence (AI) and machine learning (ML), particularly deep learning-based image analysis, have demonstrated remarkable potential in automating the detection and classification of skin lesions with performance levels approaching or surpassing that of experienced dermatologists [@khan2021multi], [@adegun2020fcn]. Such systems leverage large annotated datasets to learn discriminative features directly from dermoscopic or clinical images, enabling fast, scalable, and cost-effective screening.

This research seeks to harness these technological advancements to develop a skin lesion detection and classification system capable of accurately identifying multiple common skin lesion types. The proposed system integrates a convolutional neural network (CNN) trained on diverse, high-quality datasets sourced from publicly available repositories such as Kaggle and curated medical image databases like DermNetNZ. In addition to the AI model, the system will include a graphical user interface (GUI) for clinical use, a command-line interface (CLI) for research purposes, and a mobile application to extend accessibility to rural and underserved communities. This comprehensive approach aims to bridge the diagnostic gap, improve early detection rates, and contribute to the broader objective of reducing the dermatological disease burden in Cameroon and similar contexts.

## Background to the Problem

Dermatological diseases represent one of the most common categories of health complaints worldwide, with conditions ranging from self-limiting skin irritations to life-threatening malignancies. The World Health Organization (WHO) has repeatedly emphasized that skin diseases are among the top ten causes of non-fatal disease burden globally, and in certain regions of sub-Saharan Africa, they are among the most frequent reasons for outpatient consultations [@hay2006skin], [@van2005common]. While conditions like melanoma and basal cell carcinoma dominate skin cancer statistics in developed nations, the disease landscape in Africa and particularly Cameroon is more heterogeneous, encompassing a mix of infectious, inflammatory, and neoplastic disorders.

Traditionally, diagnosis of skin lesions has relied heavily on visual inspection by a dermatologist, often supplemented by dermoscopic evaluation or histopathological examination for suspicious cases [@yap2018multimodal]. However, this process is inherently subjective and highly dependent on the clinician’s expertise and experience. In many LMICs, including Cameroon, the ratio of dermatologists to the population is critically low, often less than one dermatologist per million inhabitants, leading to substantial diagnostic delays. Moreover, general practitioners and nurses, who often serve as first-line healthcare providers, may lack specialized training in dermatology, further compounding the risk of misdiagnosis or missed diagnoses.

The advent of AI in medical imaging, particularly the application of convolutional neural networks (CNNs) to dermoscopic and clinical images, has opened new possibilities for addressing these challenges [@harangi2018skin], [@mahbod2019skin]. CNNs can automatically extract hierarchical features from raw image data, allowing them to differentiate between lesion types with minimal human intervention. Studies have demonstrated that AI-based diagnostic tools can achieve diagnostic accuracy comparable to or exceeding that of experienced dermatologists in controlled settings [@albahar2019skin], [@jinnai2020development]. 

Despite these advancements, most existing AI models for skin lesion classification have been trained and validated on datasets that predominantly contain images from lighter-skinned populations in Europe, North America, and Australia [@gouda2022detection]. This raises concerns about model generalizability to populations with darker skin tones, such as those in sub-Saharan Africa. Additionally, existing research has often focused on detecting malignant lesions, particularly melanoma, with limited emphasis on the broader spectrum of common lesions prevalent in African contexts, such as eczema, tinea infections, or Kaposi’s sarcoma.

This project responds to these gaps by developing a multi-class lesion classification system specifically curated to include a diverse set of common skin conditions affecting African populations. The dataset compilation process involves selecting high-quality images from multiple Kaggle repositories and supplementing them with clinically verified images from DermNetNZ, ensuring representation across various lesion categories and skin tones. Through this approach, the proposed system aims to offer a clinically relevant, context-sensitive diagnostic support tool that addresses both the technical challenges of AI implementation and the pressing healthcare needs of the target population.

## Problem Statement

The early and accurate diagnosis of skin lesions remains a critical public health challenge in Cameroon and across much of sub-Saharan Africa. While skin lesions may appear trivial in their initial stages, certain forms such as malignant melanomas, squamous cell carcinomas, and basal cell carcinomas, can rapidly progress to life-threatening stages if left untreated. In parallel, other non-malignant but common conditions, such as fungal infections, eczema, and psoriasis, can cause significant discomfort, social stigma, and economic loss due to chronicity and recurrence.

In many urban centers of high-income countries, advanced diagnostic services and dermatology specialists are accessible, enabling early detection and management. However, in Cameroon, the number of dermatologists is grossly inadequate relative to the population size, with some regions having no specialist at all [@hay2006skin], [@van2005common]. This shortage forces patients to rely on general practitioners or traditional healers, which often leads to delayed diagnoses, mismanagement, or complete neglect of skin-related health issues.

Furthermore, conventional diagnostic workflows are limited by two key barriers:  
1. **Geographic accessibility** – Many patients in rural areas must travel long distances to reach healthcare facilities, resulting in missed opportunities for early diagnosis.  
2. **Resource limitations** – Even in urban hospitals, dermoscopic imaging equipment and histopathological services are often scarce or prohibitively expensive.

Recent developments in artificial intelligence, specifically convolutional neural networks (CNNs), have shown promise in automating skin lesion detection and classification with high accuracy [@khan2021multi], [@adegun2020fcn]. Nonetheless, most existing models are trained on datasets from lighter-skinned populations and focus primarily on malignant lesions, limiting their applicability in African contexts where lesion diversity and skin tone variations differ significantly [@gouda2022detection].

The central problem, therefore, is the absence of an accessible, accurate, and context-specific diagnostic tool for multiple types of skin lesions prevalent in Cameroon. There is a need for an integrated system that combines AI-powered lesion detection with user-friendly interfaces, ranging from clinical desktop applications to mobile apps that can bridge the diagnostic gap between rural patients, urban hospitals, and research institutions.

## Objectives of the Study

The overarching aim of this study is to develop a comprehensive skin lesion detection and classification system that leverages deep learning techniques to address the diagnostic challenges faced in Cameroon and similar low-resource settings.

### General Objective
To design and implement an AI-driven system capable of accurately detecting and classifying multiple types of common skin lesions, with deployment across desktop, command-line, and mobile platforms to improve diagnostic accessibility.

### Specific Objectives
\begin{enumerate}
    \item To compile and curate a diverse, high-quality dataset of common skin lesion images from multiple open-access sources, including Kaggle repositories and the DermNetNZ medical image database.
    \item To preprocess and augment image data to enhance model robustness..
    \item To train a convolutional neural network (CNN) model optimized for multi-class lesion classification, ensuring high performance on both malignant and non-malignant categories.
    \item To develop a command-line interface (CLI) for research and model testing purposes.
    \item To design and implement a mobile application capable of performing on-device lesion classification for remote and rural healthcare access.
    \item To evaluate the system's performance against standard diagnostic accuracy metrics, including sensitivity, specificity, and overall classification accuracy.
    \item To assess the feasibility of integrating the system into existing telemedicine frameworks in Cameroon.
\end{enumerate}


## Scope of the Study

This study focuses on the development of a skin lesion detection and classification system tailored for the Cameroonian healthcare context, while incorporating global best practices in AI-assisted dermatological diagnosis. The scope of the research spans four key dimensions: the dataset, the technical solution, the deployment platforms, and the evaluation process.

From a **data perspective**, the system will be trained and validated using a carefully curated dataset compiled from multiple publicly available repositories on Kaggle, supplemented with high-quality dermatological images sourced from DermNetNZ. These sources offer a broad spectrum of lesion categories, ranging from malignant cancers such as melanoma and squamous cell carcinoma to non-malignant conditions like eczema, psoriasis, and fungal infections. Selection criteria will prioritize image clarity, correct annotation, diversity of skin tones, and representation of lesion variations to ensure the model's applicability across a wide demographic.

From a **technical perspective**, the system will employ a convolutional neural network (CNN) architecture fine-tuned for multi-class classification. Advanced preprocessing techniques, such as data augmentation and normalization, will be applied to enhance the model’s generalizability across different imaging conditions. While the primary focus is on image-based diagnosis, the system is not intended to replace histopathological confirmation, which remains the gold standard for definitive lesion classification.

From a **deployment perspective**, the project encompasses three interfaces:

1. A **Command-Line Interface (CLI)**, primarily intended for researchers and developers for testing and evaluating the AI model.  
2. A **Mobile Application**, optimized for both offline and online usage, to enable healthcare workers and patients in rural areas to perform preliminary lesion assessments without constant internet connectivity.  


From an **evaluation perspective**, the model will be tested using standard performance metrics, including accuracy, sensitivity, specificity, and confusion matrix analysis. The evaluation will emphasize the system’s ability to handle variations in lesion presentation due to differences in skin pigmentation, image quality, and environmental lighting.

The project does not aim to cover the entire spectrum of dermatological conditions, rare or highly complex lesions requiring specialized diagnostic equipment fall outside the intended operational scope. Instead, the focus is on delivering a reliable, accessible, and scalable solution for the most common and clinically significant skin lesions encountered in Cameroon and similar resource-limited environments.

## Significance of the Study

Skin diseases are among the most common health concerns globally, with billions of people affected each year, spanning all socioeconomic groups [@hay2006skin]. In Cameroon and much of sub-Saharan Africa, the impact of skin lesions is amplified by a combination of high prevalence, limited specialist care, and widespread misinformation about skin health. Misdiagnosed or untreated lesions, whether malignant or non-malignant, can lead to severe health complications, disfigurement, psychological distress, and in the case of cancers, increased mortality rates.

The significance of this study lies in its potential to bridge the diagnostic gap through a context-specific, AI-driven approach. By leveraging deep learning algorithms and multi-platform deployment, the system offers a means of providing timely and accurate lesion assessment to populations that currently lack access to dermatological expertise. For healthcare providers, this could translate to earlier interventions, better patient outcomes, and a reduction in the burden on tertiary healthcare facilities.

From a **public health perspective**, the project addresses a critical need in preventive care. Early detection and classification can significantly reduce treatment costs and improve survival rates in malignant cases, while minimizing chronic complications in non-malignant cases. Moreover, the system’s mobile deployment makes it a practical tool for community health workers conducting outreach in rural and peri-urban areas.

From a **technological perspective**, the research contributes to the growing field of AI in medical imaging by demonstrating how existing machine learning methods can be adapted to underrepresented populations. Many existing AI models for skin lesion classification are trained predominantly on lighter-skinned datasets, making them less effective for darker skin tones [@gouda2022detection]. By incorporating diverse skin tone representation from datasets like DermNetNZ and Kaggle repositories, this study advances the inclusivity and fairness of medical AI systems.

From an **academic perspective**, the project provides a valuable reference for future studies in both computer vision and health informatics within the African context. The integration of a research-oriented CLI, a mobile health application, and a clinical GUI sets a precedent for multi-platform medical AI systems designed for low-resource settings.

Ultimately, the study seeks to contribute toward Sustainable Development Goal 3 (Good Health and Well-being) by enabling accessible, affordable, and high-quality dermatological diagnostics in regions where such services are currently limited or absent.


### 1.7 Limitations of the Study

While this study seeks to develop a comprehensive, AI-powered skin lesion detection and classification system, several constraints inevitably shape the scope and potential impact of the research. First, the dataset, although carefully curated from high-quality open-access sources such as Kaggle repositories and the DermNetNZ medical image database, may not capture the full diversity of skin lesion presentations across all ethnic groups and age categories. This limitation is particularly relevant for sub-Saharan African populations, where variations in skin pigmentation can influence lesion visibility and morphology, potentially impacting model generalization [@hay2006skin], [@van2005common].

Second, although image preprocessing and augmentation techniques are employed to mitigate overfitting and improve robustness, the absence of histopathological confirmation for all dataset images introduces an inherent diagnostic uncertainty. Clinical image-based diagnosis, while valuable, cannot entirely substitute for biopsy-confirmed ground truth, especially in differentiating visually similar lesion types [@zafar2023skin].

Third, computational resource limitations constrain the complexity and scale of model experimentation. While transfer learning with established CNN architectures, such as ResNet, offers strong baseline performance, exploring more computationally intensive models or ensemble methods may be restricted due to hardware constraints. This also impacts the breadth of hyperparameter optimization that can be conducted within the project timeline.

Fourth, the current implementation focuses primarily on classification accuracy and does not yet incorporate a complete clinical decision support framework, such as integration with electronic health records (EHRs) or automated referral systems. Similarly, the system’s deployment is confined to a mobile application and a research-oriented command-line interface, without the immediate inclusion of a graphical interface for clinical integration, an enhancement reserved for future development phases.

Finally, while the study includes performance evaluation using standard diagnostic metrics (e.g., sensitivity, specificity, overall accuracy), real-world clinical validation with dermatologists or in live telemedicine settings is beyond the scope of the present work. This limits immediate translation into routine healthcare workflows but provides a foundation for subsequent validation studies.

### 1.8 Organization of the Study

The remainder of this thesis is organized into five chapters, each systematically addressing a core component of the research.

- **Chapter 1 – Introduction**: Provides an overview of the research problem, contextual background, study objectives, scope, significance, and limitations, setting the stage for the investigation.
- **Chapter 2 – Literature Review**: Presents a comprehensive examination of existing studies on skin lesion detection and classification, machine learning and deep learning techniques applied to medical imaging, and relevant mobile health (mHealth) application frameworks. This chapter critically evaluates the strengths and weaknesses of prior approaches, identifying gaps that this study seeks to address.
- **Chapter 3 – Methodology**: Describes the research design, dataset collection and curation process, preprocessing and augmentation strategies, CNN architecture selection, training procedures, and performance evaluation metrics. It also outlines the mobile application and CLI implementation details.
- **Chapter 4 – Results and Discussion**: Reports and analyzes experimental results, including classification performance, error analysis, and comparative evaluation against existing methods. The discussion interprets these findings in the context of the study objectives and broader literature.
- **Chapter 5 – Conclusion and Future Work**: Summarizes key findings, reiterates the contributions of the study, and outlines limitations alongside recommended directions for future research, including potential clinical integration and large-scale deployment strategies.

This structured organization ensures a logical progression from problem identification through methodological implementation to empirical validation and future considerations, facilitating clarity and coherence for both technical and non-technical readers.


\newpage

# Chapter 2: Literature Review

## Introduction

The human skin, as the largest organ of the body, serves as the first line of defense against environmental insults, pathogens, and physical trauma. It performs essential physiological roles including thermoregulation, sensory perception, and immunological protection. However, the skin is susceptible to a wide range of pathological conditions, collectively referred to as skin lesions, which can significantly impair an individual’s quality of life and, in severe cases, become life-threatening [@hay2006skin]. These lesions may arise from infectious agents, autoimmune disorders, genetic anomalies, or prolonged environmental exposure, with their clinical presentation varying from benign and self-limiting forms to aggressive malignancies [@van2005common].

Globally, skin diseases constitute a substantial public health challenge, ranking among the top causes of non-fatal disease burden. According to the Global Burden of Disease Study, conditions such as eczema, acne, and fungal infections collectively affect billions of individuals worldwide, while skin cancers contribute significantly to morbidity and mortality in certain regions [@zafar2023skin]. In sub-Saharan Africa, and specifically in Cameroon, the prevalence of skin lesions is amplified by climatic factors such as high ultraviolet (UV) index, tropical humidity, and widespread infectious disease exposure, combined with limited access to dermatological specialists and diagnostic facilities [@hay2006skin]. Rural communities often face the most acute challenges, where early detection and treatment are hindered by geographical, infrastructural, and socioeconomic constraints.

Recent advances in Artificial Intelligence (AI), particularly in computer vision, have opened promising avenues for automated skin lesion analysis. Machine learning and deep learning techniques, particularly Convolutional Neural Networks (CNNs), have demonstrated superior performance in differentiating between lesion types, sometimes rivalling trained dermatologists in diagnostic accuracy [@kassem2021machine], [@ogudo2023optimal]. Leveraging such tools in low-resource settings could significantly enhance early diagnosis, improve treatment outcomes, and reduce the long-term health and economic burdens associated with skin diseases.

This chapter reviews the existing literature on skin lesion types, their epidemiology, and the role of AI in dermatological diagnostics, with particular emphasis on the African context. It also outlines the technical underpinnings of CNN-based approaches, dataset challenges, and existing AI-enabled systems for skin lesion detection.


## Overview of Skin Lesions and Skin Cancer

Skin lesions represent a broad spectrum of structural or functional abnormalities affecting the skin’s epidermal, dermal, or subcutaneous layers. They are typically classified according to their clinical appearance, etiology, and pathological significance, ranging from benign, non-cancerous conditions to malignant cancers that pose significant health risks [@zafar2023skin]. Understanding the characteristics, prevalence, and diagnostic challenges associated with each category is crucial for designing AI-assisted diagnostic systems capable of reliable, multi-class classification across diverse lesion types.

### Non-Cancerous Lesions

Non-cancerous lesions comprise the majority of dermatological cases encountered in both primary and specialized care. These include inflammatory conditions such as eczema and psoriasis, infectious diseases like fungal infections and bacterial dermatoses, pigmentary disorders such as vitiligo, and benign growths including seborrheic keratoses and skin tags [@hay2006skin]. While these lesions are typically non-fatal, they can cause chronic discomfort, psychological distress, and social stigma, especially when affecting visible body areas.

In Africa, the high prevalence of infectious dermatoses is closely linked to environmental and socioeconomic conditions. Fungal infections such as tinea capitis are particularly common among children in rural and peri-urban areas due to overcrowding, limited hygiene facilities, and humid climatic conditions [@van2005common]. Similarly, bacterial skin infections like impetigo and cellulitis are widespread, often arising as secondary infections in individuals with compromised skin barriers from insect bites, eczema, or other dermatological conditions.

Chronic inflammatory diseases such as eczema and psoriasis, though less prevalent than infectious dermatoses, represent a significant health burden due to their recurrent nature and the need for long-term management. In many low-resource settings, limited access to dermatologists and diagnostic tools leads to misdiagnosis, inappropriate treatment, and poor disease control. Pigmentary disorders such as vitiligo and post-inflammatory hyperpigmentation are also of particular concern in African populations, where cultural perceptions and stigma may influence healthcare-seeking behavior [@hay2006skin].

From a diagnostic perspective, the visual similarity between non-cancerous and cancerous lesions can pose a challenge, particularly for general practitioners without specialized dermatological training. AI-driven image analysis tools have the potential to assist in differentiating these lesions, improving diagnostic accuracy in settings where specialist input is scarce.

### Cancerous Lesions

Cancerous lesions, though less common than non-cancerous forms, are of critical concern due to their potential for metastasis and mortality. The most prevalent malignant skin cancers include melanoma, squamous cell carcinoma (SCC), and basal cell carcinoma (BCC). While melanoma is less frequent in darker skin tones, its prognosis is often poorer in African populations due to late-stage diagnosis [@zafar2023skin]. SCC and BCC, on the other hand, may occur in sun-exposed or chronically damaged skin regardless of skin tone.

Globally, skin cancers represent a significant proportion of all cancer diagnoses, with an estimated 1.5 million new cases annually [@kassem2021machine]. In high-income countries, public health campaigns and widespread access to dermatological care have improved early detection rates, leading to better survival outcomes. In contrast, in many African countries, including Cameroon, public awareness of skin cancer remains low, and access to diagnostic biopsies and histopathology services is limited. Consequently, patients often present with advanced disease stages, reducing treatment options and survival prospects.

Risk factors for skin cancer in African populations include albinism, chronic scarring from burns or ulcers, prolonged exposure to UV radiation (especially among outdoor workers), and certain viral infections such as human papillomavirus (HPV). Individuals with albinism, in particular, face a dramatically elevated risk of developing SCC due to the absence of protective melanin in the skin.

Diagnosing skin cancer in low-resource settings is challenging due to both infrastructural and human resource constraints. Dermoscopy, histopathology, and other confirmatory diagnostic modalities may be unavailable outside urban tertiary hospitals. In such contexts, mobile AI-assisted diagnostic tools can play an instrumental role in triaging suspicious lesions, guiding referrals, and facilitating earlier intervention.

## Role of Artificial Intelligence in Dermatology

Artificial Intelligence (AI) has emerged as a transformative force in medical diagnostics, with dermatology standing out as a field particularly well-suited to AI-driven interventions. This suitability stems from the inherently visual nature of dermatological assessment, where clinical diagnosis often relies heavily on visual inspection of lesion morphology, color, texture, and distribution patterns. AI systems, especially those based on computer vision, can replicate and, in some cases, surpass human pattern recognition capabilities by analyzing large volumes of annotated images [@kassem2021machine], [@ogudo2023optimal].

In recent years, deep learning algorithms have demonstrated diagnostic performance comparable to, and occasionally exceeding, that of board-certified dermatologists [@esteva2017dermatologist]. These advancements have been facilitated by the availability of large-scale annotated image datasets, improvements in computational power, and algorithmic innovations in neural network architectures. AI-powered systems have been successfully developed to identify and differentiate between multiple skin lesion types, including both malignant and non-malignant conditions, with high sensitivity and specificity.

Beyond diagnostic accuracy, AI offers significant advantages in scalability and accessibility. Once trained, AI models can be deployed on a wide range of devices from high-performance clinical workstations to mobile smartphones, making them particularly valuable in low-resource environments. In rural areas of Cameroon, for example, where access to dermatologists is limited, AI-powered mobile applications could enable preliminary screening and triage, directing patients with suspicious lesions to specialized care.

Another important role of AI in dermatology lies in **decision support**. AI systems can assist clinicians by highlighting regions of interest, providing probability scores for different lesion classes, and integrating clinical metadata (such as patient age, lesion history, and risk factors) into predictive models. This reduces the likelihood of oversight in busy clinical environments and supports more consistent diagnostic outcomes.

Furthermore, AI-based lesion analysis is not limited to classification. Emerging research is exploring its application in lesion segmentation, disease progression tracking, and even predictive analytics for treatment response. Such capabilities could support not only individual patient management but also large-scale epidemiological surveillance.

Despite these strengths, AI adoption in dermatology is not without challenges. Issues such as dataset bias, lack of diverse representation (especially for darker skin tones), and limited interpretability of deep learning models can affect trust and clinical uptake [@gouda2022detection]. Ethical and regulatory considerations ranging from patient data privacy to liability in the event of misdiagnosis, also remain critical hurdles. Addressing these concerns will be essential for ensuring that AI complements rather than replaces clinical judgment, particularly in sensitive medical contexts.

## Convolutional Neural Networks (CNNs)

Convolutional Neural Networks (CNNs) represent the cornerstone of modern computer vision and have become the dominant architecture for image classification tasks, including dermatological image analysis. Inspired by the organization of the animal visual cortex, CNNs are designed to automatically learn hierarchical feature representations directly from raw pixel data, eliminating the need for manual feature engineering [@lecun2015deep].

A typical CNN architecture comprises several key components:

1. **Convolutional Layers** – These layers apply a series of learnable filters to the input image, producing feature maps that capture spatial hierarchies such as edges, textures, and shapes. Early layers detect simple patterns, while deeper layers learn more complex and abstract features relevant to classification.
   
2. **Pooling Layers** – Pooling operations (e.g., max pooling, average pooling) reduce the spatial dimensions of feature maps, thereby decreasing computational load and controlling overfitting while retaining the most salient information.

3. **Activation Functions** – Non-linear activation functions, such as ReLU (Rectified Linear Unit), introduce non-linearity into the network, enabling it to learn complex decision boundaries.

4. **Fully Connected Layers** – These layers interpret the high-level features extracted by convolutional and pooling layers, ultimately producing class probability scores through a softmax or sigmoid activation function.

The strength of CNNs in dermatology lies in their ability to extract discriminative features from lesion images, even in the presence of significant variability in lesion size, shape, color, and background noise. This is particularly important for differentiating between lesions with subtle morphological differences, such as differentiating an atypical mole from early-stage melanoma.

In the context of skin lesion classification, CNNs have been successfully applied to both binary classification tasks (e.g., benign vs malignant) and multi-class classification covering a range of lesion types [@kassem2021machine]. Their performance is further enhanced through techniques such as **data augmentation** (rotations, flips, scaling, color jittering) and **regularization** (dropout, weight decay), which improve generalization and robustness.

However, training CNNs from scratch requires large, balanced datasets, an obstacle in medical imaging where data is often scarce and unevenly distributed across classes. This limitation has driven widespread adoption of **transfer learning**, wherein CNN architectures pre-trained on large general-purpose datasets (such as ImageNet) are fine-tuned on specific medical datasets. Models like ResNet, Inception, and EfficientNet have been extensively leveraged in this manner, yielding strong results even with limited medical image data.

For this project, CNNs form the foundational architecture of the lesion detection and classification system, enabling automated feature extraction and classification in a manner that is both scalable and adaptable to diverse deployment environments. Their proven success in similar tasks makes them a natural choice for addressing the diagnostic challenges associated with skin lesions in Cameroon and other low-resource settings.

## Transfer Learning and ResNet Models

Training deep learning models from scratch typically requires vast datasets containing millions of annotated images. In medical imaging, however, such large-scale datasets are rare due to privacy concerns, the cost of expert annotations, and the limited prevalence of certain conditions [@gouda2022detection]. This scarcity makes **transfer learning** a practical and effective approach for developing high-performing models with limited domain-specific data.

Transfer learning involves leveraging a model pre-trained on a large, general-purpose dataset such as ImageNet, which contains over 14 million images across 1,000 classes and adapting it to a new but related task [@lecun2015deep]. In this paradigm, the lower layers of the pre-trained model, which capture generic features like edges, textures, and shapes, are retained, while the higher layers, which learn task-specific features, are fine-tuned on the target medical dataset. This approach reduces training time, lowers computational requirements, and mitigates the risk of overfitting.

Among the various architectures used for transfer learning, **Residual Networks (ResNet)** have become particularly prominent due to their ability to train very deep networks without succumbing to the vanishing gradient problem [@he2016deep]. ResNet’s innovation lies in its *residual blocks*, which introduce shortcut connections that allow gradients to flow more easily through the network during backpropagation. This architecture enables the training of models with hundreds of layers while maintaining stability and accuracy.

ResNet-18, ResNet-34, and ResNet-50 are among the most widely used variants in medical imaging applications, each offering a trade-off between computational complexity and representational power. For skin lesion classification, ResNet architectures have consistently demonstrated strong performance, particularly when fine-tuned with domain-specific data and augmented through preprocessing techniques such as rotation, scaling, and color normalization [@kassem2021machine].

In the context of this study, ResNet-18 was selected for its balance between accuracy and computational efficiency, making it suitable for deployment on both research environments and resource-constrained devices like smartphones. Transfer learning with ResNet-18 allows the model to benefit from robust, pre-learned visual features while adapting to the nuances of dermatological imagery from diverse sources, including those representing darker skin tones and non-cancerous lesions that are often underrepresented in global datasets.


## Dataset Challenges in Medical Imaging

The success of AI systems in medical imaging is intrinsically tied to the quality, diversity, and representativeness of the datasets used for training and evaluation. In dermatology, this presents several significant challenges.

**1. Data Scarcity and Class Imbalance** – High-quality, annotated dermatological datasets are limited, particularly for rare conditions and underrepresented demographics. Publicly available datasets such as those on Kaggle or DermNetNZ often contain disproportionate numbers of images for certain lesion types, leading to class imbalance. Models trained on such datasets risk becoming biased toward majority classes, resulting in reduced accuracy for minority categories [@gouda2022detection].

**2. Limited Skin Tone Representation** – Many benchmark datasets are heavily skewed toward lighter skin tones, reflecting their origins in high-income, predominantly Caucasian populations [@gouda2022detection]. This lack of diversity can lead to systematic biases, where models perform well on lighter skin but poorly on darker tones—a critical limitation when deploying AI tools in African contexts.

**3. Variability in Image Acquisition** – Images in dermatology can be captured under a wide range of conditions, including variations in lighting, background, focus, and resolution. Differences in equipment from professional dermatoscopes to smartphone cameras, introduce further heterogeneity, making model generalization more difficult [@zafar2023skin]. Robust preprocessing pipelines, including color correction, normalization, and augmentation, are essential to mitigate these effects.

**4. Annotation Quality and Consistency** – Accurate labeling of lesion types often requires expert dermatological input. In public datasets, annotations may be inconsistent or based solely on visual inspection rather than biopsy-confirmed diagnoses. This introduces noise into the training data, potentially lowering model performance [@van2005common].

**5. Ethical and Privacy Concerns** – Medical image datasets must comply with strict privacy regulations to protect patient identities. This can limit the sharing of comprehensive datasets, particularly those including metadata such as patient age, sex, and medical history. De-identification processes, while necessary, may also remove potentially valuable contextual information.

For this project, these challenges were addressed through **multi-source dataset compilation**, selecting high-quality images from multiple Kaggle repositories and the DermNetNZ image database. Images were chosen based on clarity, annotation reliability, and diversity in lesion presentation. Preprocessing steps, including augmentation techniques, were applied to improve model robustness. While this approach does not entirely eliminate dataset-related limitations, it provides a strong foundation for training a model capable of handling real-world variability in skin lesion imagery.


### Review of Existing Systems

The development of automated skin lesion detection systems has evolved significantly over the past three decades, transitioning from rule-based image processing algorithms to advanced deep learning frameworks capable of multi-class classification. Early computer-aided diagnosis (CAD) systems, developed in the late 1990s and early 2000s, primarily relied on handcrafted features such as color histograms, shape descriptors, and texture measures, combined with classical classifiers like Support Vector Machines (SVMs) and k-Nearest Neighbors (k-NN). While these systems achieved moderate success in controlled environments, their reliance on manually engineered features made them highly sensitive to variations in lighting, resolution, and lesion morphology [@gouda2022detection].

Over the past decade, deep learning, particularly Convolutional Neural Networks (CNNs) has revolutionized dermatological image analysis. CNN-based models eliminate the need for manual feature extraction by learning hierarchical feature representations directly from pixel data [@lecun2015deep]. Notable milestones include the work of Esteva et al., who demonstrated dermatologist-level classification of skin cancer using a CNN trained on over 129,000 clinical images [@esteva2017dermatologist], and the introduction of transfer learning approaches that significantly reduce the data requirements for effective model training [@he2016deep].

Several prominent publicly available systems illustrate the current state of the art. For example, the **ISIC (International Skin Imaging Collaboration)** challenge platforms have driven substantial progress by providing standardized datasets and benchmarking opportunities for skin lesion classification and segmentation tasks. Solutions from top-performing teams often integrate deep CNN architectures such as ResNet, Inception, and EfficientNet, combined with ensemble learning and advanced data augmentation techniques.

In commercial and practical deployment contexts, mobile applications such as *SkinVision* and *Miiskin* leverage AI to provide lesion risk assessments directly to users via smartphone cameras. While these tools have expanded public access to preliminary screening, they often focus on binary classification (e.g., suspicious vs. non-suspicious) and may not comprehensively cover the range of benign and malignant lesion types relevant in diverse populations, particularly in low-resource settings like Cameroon.

Within academic research, several studies have explored multi-class lesion classification. Kassem et al. proposed a CNN-based framework achieving high accuracy across seven lesion classes in the HAM10000 dataset [@kassem2021machine], while Ogudo et al. adapted a transfer learning approach for African skin tones, underscoring the importance of dataset diversity [@ogudo2023optimal]. These studies highlight the growing focus on inclusivity and generalizability in AI dermatology systems.

Despite these advancements, limitations persist. Many existing systems are trained on datasets that lack representation of darker skin tones, have a narrow lesion type coverage, or fail to address deployment constraints such as offline functionality and low computational resources. Furthermore, while commercial solutions often reach end-users quickly, they may not undergo the same level of clinical validation or peer-reviewed scrutiny as academic research outputs.


## Research Gap

While the progress in AI-powered dermatological diagnostics over the last decade has been remarkable, several gaps remain, particularly in the context of African healthcare systems.

**1. Dataset Representation** – Most high-performing models are trained on datasets dominated by images from lighter skin tones. This limits their diagnostic accuracy when applied to African populations, where lesion appearance can differ significantly due to higher melanin content and unique environmental exposure patterns [@gouda2022detection]. The lack of comprehensive datasets covering both malignant and non-malignant lesions in darker skin is a critical barrier.

**2. Multi-Class Coverage** – Many commercial and academic systems prioritize melanoma detection due to its high mortality rate in fair-skinned populations. However, in African contexts, non-cancerous lesions, such as fungal infections, eczema, and pigmentary disorders, constitute the majority of dermatological cases and therefore require equal diagnostic attention.

**3. Deployment in Low-Resource Settings** – Existing systems often assume reliable internet connectivity and high-performance computing infrastructure, making them unsuitable for rural or underserved regions. Offline-capable, computationally efficient models are needed to bridge this gap.

**4. Clinical Integration and Trust** – Limited collaboration between AI developers and healthcare providers in Africa has slowed the integration of AI tools into clinical workflows. Moreover, clinicians may be hesitant to adopt AI systems without clear interpretability, validation on local datasets, and regulatory approval.

**5. Comprehensive Diagnostic Workflow** – While classification accuracy is a major focus of existing research, other aspects of the diagnostic process such as lesion segmentation, tracking over time, and integration with patient health records, remain underexplored in resource-constrained contexts.

This study addresses these gaps by developing a **multi-class skin lesion classification system** optimized for deployment in Cameroon. The approach combines a curated dataset from multiple open-access sources (Kaggle repositories and DermNetNZ), robust preprocessing and augmentation, transfer learning using ResNet-18, and deployment pathways that accommodate both research and mobile application environments. By doing so, it aims to improve diagnostic accuracy across a broader range of lesions, enhance representation for darker skin tones, and enable accessibility in low-resource healthcare settings.


## Summary

This chapter has provided a comprehensive review of the literature relevant to the development of AI-powered skin lesion detection and classification systems. The discussion began with an overview of skin lesions, distinguishing between non-cancerous and cancerous categories, and emphasizing their prevalence and diagnostic challenges both globally and within the African context. The role of AI in dermatology was examined, with a particular focus on CNN architectures, transfer learning strategies, and the ResNet model family, which has proven highly effective in medical imaging tasks.

Dataset challenges in medical imaging were explored in detail, highlighting issues such as class imbalance, limited representation of darker skin tones, variability in image acquisition, and annotation quality. The review of existing systems illustrated the evolution of lesion detection technologies from early handcrafted-feature approaches to modern deep learning-based solutions, while also identifying their limitations in terms of inclusivity, deployment feasibility, and comprehensive lesion coverage.

Finally, the research gap analysis underscored the need for multi-class, skin-tone-inclusive, resource-efficient diagnostic systems that can be deployed effectively in low-resource settings such as Cameroon. The following chapter will present the methodology adopted for this study, detailing the dataset compilation, preprocessing, model training, evaluation, and deployment strategies used to develop the proposed skin lesion classification system.


\newpage

# Chapter 3: Methodology

## Introduction

The methodology adopted for this research project provides a systematic framework for developing, training, and evaluating a skin lesion detection and classification system. The primary objective of the methodology is to ensure that each stage of the project, from data acquisition to model deployment is structured, reproducible, and grounded in established machine learning best practices. The complexity of dermatological image analysis, combined with the variability of skin lesion types, demands a rigorous approach to both data handling and algorithmic design. In this study, the methodology not only addresses the technical aspects of convolutional neural network (CNN) implementation but also incorporates considerations for application development, user interaction, and deployment.

Skin lesion classification presents unique challenges. Unlike standard image classification tasks, dermatological images often exhibit high intra-class variability and subtle inter-class differences. Conditions such as **melanoma** and **nevus** can appear visually similar under certain imaging conditions, while diseases like **chickenpox**, **measles**, and **monkeypox** may share overlapping lesion morphologies. This complexity is further compounded by variations in image acquisition methods, lighting conditions, skin tones, and anatomical locations. A robust methodology must therefore be capable of addressing these challenges through appropriate data preprocessing, feature extraction, and model optimization techniques.

The development of this system follows a structured lifecycle that draws upon the **CRoss Industry Standard Process for Data Mining (CRISP-DM)** methodology, widely recognized for its flexibility and applicability to data science projects. The CRISP-DM model consists of six iterative phases: **Business Understanding**, **Data Understanding**, **Data Preparation**, **Modeling**, **Evaluation**, and **Deployment**, each of which is adapted to the specific context of this project. This structure facilitates not only the creation of a high-performing CNN-based classifier but also ensures that the final product can be integrated into practical diagnostic workflows through both a Command-Line Interface (CLI) and a mobile application.

A key differentiator of this project, compared to many prior works [@ogudo2023optimal; @khan2021multi; @zafar2023skin], is the scope of the dataset. While datasets such as HAM10000 primarily focus on malignant and benign skin tumors, the dataset in this study encompasses a broader range of dermatological conditions, including viral, bacterial, fungal, autoimmune, and parasitic skin diseases. This comprehensive dataset, covering **33 distinct categories** such as **Acne**, **Actinic Keratosis**, **Ringworm**, **Leprosy**, **Basal Cell Carcinoma**, and **Vitiligo**, allows for a more inclusive diagnostic support system capable of handling diverse clinical scenarios.

The methodology outlined in this chapter provides the foundation for:

- Efficient preprocessing and augmentation techniques to enhance dataset diversity.
- Fine-tuning of a **ResNet-18** architecture pre-trained on ImageNet to adapt to the specific features of dermatological imagery.
- Training strategies incorporating **class weighting**, **early stopping**, and **learning rate scheduling** to improve generalization and avoid overfitting.
- Evaluation protocols employing multiple performance metrics, including **accuracy**, **precision**, **recall**, and **F1-score**.
- Integration of the trained model into an accessible and user-friendly application environment.

Ultimately, the methodological approach ensures that the system is both technically sound and practically relevant, with the potential for deployment in clinical and teledermatology contexts.


## Project Framework and Approach

The **CRoss Industry Standard Process for Data Mining (CRISP-DM)** methodology serves as the guiding framework for the development of the skin lesion detection and classification system. Originally designed for data mining projects, CRISP-DM has been widely adapted in the field of machine learning and artificial intelligence due to its structured yet flexible nature [@ruparelia2010software; @shafiq2021literature]. The six phases of CRISP-DM, **Business Understanding**, **Data Understanding**, **Data Preparation**, **Modeling**, **Evaluation**, and **Deployment**, are not strictly linear but rather iterative, allowing for feedback loops and refinements at any stage.

### Business Understanding

The primary goal of this project is to develop an automated skin lesion classification system that can aid healthcare professionals and patients in the early detection and differentiation of dermatological conditions. The motivation stems from several factors:

1. **Rising global incidence of skin diseases** – Both malignant and non-malignant skin conditions are increasingly prevalent worldwide, with skin cancer alone affecting millions annually [@hay2006skin; @esteva2017dermatologist].
2. **Shortage of dermatologists in certain regions** – Many rural and under-resourced areas lack access to specialist care, creating a need for supportive diagnostic tools [@van2005common].
3. **Potential for teledermatology** – Mobile and cloud-based diagnostic systems can extend dermatological services to remote areas, enabling earlier interventions.

The **business objectives** for this project include:

- Developing a CNN-based classification model capable of identifying multiple dermatological conditions with high accuracy.
- Providing a CLI for researchers and dermatology students to perform batch classification, evaluation, and model experimentation.
- Creating a mobile application for non-technical users, enabling on-device or cloud-assisted skin lesion classification.
- Designing the system to be scalable for future integration with electronic medical records (EMR) and telemedicine platforms.

The **success criteria** for the project are defined by:

- Achieving a **minimum validation accuracy of 75%** across all classes.
- Demonstrating robustness in real-world conditions with varying lighting, angles, and skin tones.
- Ensuring inference times suitable for near real-time use in both CLI and mobile environments.


### Data Understanding

The dataset is a curated collection of high-resolution dermatological images representing **33 distinct categories** of skin conditions. Unlike traditional datasets such as HAM10000 [@khan2021multi], which primarily focus on tumor detection, this dataset spans multiple disease types including:

- **Viral infections** (e.g., Chickenpox, Monkeypox, Measles, Shingles)
- **Bacterial infections** (e.g., Impetigo, Leprosy, Whitlow)
- **Fungal infections** (e.g., Athlete’s foot, Ringworm, Nail fungus)
- **Parasitic infestations** (e.g., Scabies, Tungiasis, Larva Migrans)
- **Inflammatory and autoimmune conditions** (e.g., Eczema, Psoriasis, Autoimmune diseases)
- **Benign and malignant tumors** (e.g., Basal Cell Carcinoma, Squamous Cell Carcinoma, Melanoma, Seborrheic Keratosis)

The images vary in background context, lighting conditions, and anatomical site, reflecting real-world diagnostic challenges. This diversity enhances the model’s generalization capability but also necessitates careful preprocessing to normalize image characteristics. Each image is labeled according to expert annotation or verified dataset metadata, ensuring label reliability.


### Data Preparation

Data preparation is a critical stage in CRISP-DM, directly influencing model performance. For this project, data preparation involved:

- **Data cleaning** – Removing duplicate images, mislabeled samples, and corrupted files.
- **Dataset partitioning** – Splitting the dataset into training (70%), validation (15%), and testing (15%) sets to ensure robust performance evaluation.
- **Data augmentation** – Applying transformations such as random horizontal flips, small rotations, and color jitter to simulate variations in real-world conditions and mitigate overfitting [@lecun2015deep].

The final preprocessing pipeline, implemented using the **Torchvision Transforms API**, included:

- **RandomHorizontalFlip** – to account for left-right orientation differences.
- **RandomRotation (10°)** – to simulate variations in image capture angles.
- **ColorJitter** – to replicate differences in lighting and camera exposure.
- **Resize to (224×224)** – to match the input dimensions expected by ResNet-18.
- **Normalization** – using the mean and standard deviation values from ImageNet, facilitating optimal transfer learning.


### Modeling

The **Modeling** phase centered on adapting a pre-trained **ResNet-18** architecture [@he2016deep] for multi-class skin lesion classification. The transfer learning approach leveraged ImageNet-trained weights, allowing the network to benefit from generalized feature extraction capabilities while focusing fine-tuning on dermatological features. Specific modifications included:

- Unfreezing the **layer4** and **fully connected (fc)** layers for fine-tuning, while freezing earlier layers to retain learned low-level features.
- Replacing the final classification layer with a fully connected layer matching the number of classes (**33**).
- Applying **class-weighted cross-entropy loss** to address class imbalance.
- Utilizing the **Adam optimizer** with a learning rate of 0.001 and **L2 weight decay** to enhance generalization.
- Implementing a **ReduceLROnPlateau** learning rate scheduler to adaptively lower the learning rate upon performance plateaus.


### Evaluation

Evaluation metrics for the system include:

- **Accuracy** – for overall classification performance.
- **Precision, Recall, and F1-score** – for per-class performance evaluation.
- **Confusion matrix** – to visualize misclassification patterns.
- **ROC and AUC curves** – <!-- @todo (Placeholder: to be generated post-training) -->.
- **Inference time measurements** – for both CLI and mobile deployment environments.

<!-- @todo **[Placeholder for: Training Loss Curve, Training Accuracy Curve, Confusion Matrix Figure, ROC/AUC Graph]** --->

### Deployment

The **Deployment** phase of CRISP-DM for this project covers integration into:

1. **CLI tool** – enabling bulk image classification, metric computation, and dataset testing.
2. **Mobile application** – developed in **React Native**, allowing on-device image capture and cloud-assisted classification.
3. **Cloud hosting** – <!-- @todo (Placeholder: Hosting architecture to be determined—potential options include AWS EC2, Google Cloud Run, or serverless architectures pending cost and credit considerations).-->

Deployment will also involve developing user interfaces for both technical and non-technical audiences, ensuring accessibility while maintaining performance.


### CRISP-DM Iteration

CRISP-DM emphasizes iteration. During development, multiple cycles of model training, hyperparameter tuning, and evaluation were conducted. Feedback from early experimental results informed adjustments to data augmentation parameters, class weighting strategies, and model layer unfreezing policies. The iterative nature of this process ensured that each phase benefited from empirical insights, ultimately improving model robustness.

<!-- @todo **[Placeholder for CRISP-DM Process Diagram tailored to this project]**-->

## Data and Requirements Gathering

Requirements gathering is a critical stage in the development of any complex system, particularly in healthcare-oriented artificial intelligence (AI) applications. For a skin lesion detection and classification system, eliciting accurate and comprehensive requirements ensures that the technical design aligns with both medical best practices and user expectations. This phase bridges the gap between the theoretical capabilities of AI models and the practical needs of end-users, which in this case include dermatologists, general practitioners, researchers, and non-technical individuals seeking self-assessment tools. As noted by Ruparelia [@ruparelia2010software], effective requirements elicitation not only enhances system relevance but also minimizes costly redesigns during later stages of development.

The approach adopted in this project combined multiple requirement gathering methods, consistent with methodological recommendations in software engineering and health informatics research [@khan2021multi; @hay2006skin]. Using a combination of qualitative and quantitative strategies increased the robustness of our findings by allowing cross-verification of insights (triangulation) and by capturing both statistical trends and nuanced, context-specific needs.

### Interviews

Semi-structured interviews were conducted with subject-matter experts, particularly dermatologists, general practitioners, and AI researchers. The purpose of these interviews was to explore diagnostic workflows, common challenges in skin lesion assessment, and expectations for integrating automated systems into clinical and teledermatology practice. Interview questions were guided by literature on the adoption of AI in dermatology [@esteva2017dermatologist; @zafar2023skin] and covered:

- The perceived accuracy and reliability thresholds acceptable for clinical decision support tools.
- Preferred output formats (e.g., probability scores, lesion type classification, urgency recommendations).
- Integration concerns with existing patient record systems and telemedicine platforms.
- Ethical considerations, including patient consent and data privacy.

Interviews were audio-recorded, transcribed, and coded for thematic analysis in later stages.

### Surveys and Questionnaires

Two online survey instruments were designed, one targeting technical and health professionals, and another aimed at non-technical individuals. The former included domain-specific questions regarding AI model transparency, explainability, and integration with clinical workflows, while the latter focused on usability, trust, and perceived usefulness of the proposed system.

The surveys comprised both closed-ended questions (for quantitative analysis) and open-ended prompts (for qualitative insights). Distribution was carried out via professional mailing lists, social media groups, and university networks. In line with Hay et al. [@hay2006skin], survey design incorporated clear definitions of medical terms to ensure comprehension among non-specialist respondents.

### Documentation Review

In addition to primary data collection, a review of relevant documentation was undertaken. This included:

- Published clinical guidelines for skin cancer detection and management.
- Existing research on automated lesion detection and classification [@ogudo2023optimal; @kassem2021machine].
- Technical specifications of public skin lesion datasets such as HAM10000 [@tschandl2018ham10000].
- Regulatory standards related to AI in healthcare, including data protection protocols.

The documentation review informed the selection of lesion categories, the choice of evaluation metrics, and constraints for model deployment.

### Focus Groups

Focus groups were organized with a mixed composition of technical experts, medical practitioners, and potential end-users. Unlike individual interviews, focus groups facilitated dynamic discussions that revealed collective priorities and concerns. For example, non-technical users expressed apprehension about over-reliance on automated outputs without human oversight, whereas clinicians emphasized the importance of false negative minimization over overall accuracy.

### Synthesis of Findings

Findings from all methods were synthesized using a multi-step process:

1. Extraction of key points from each method.
2. Cross-referencing to identify recurring requirements.
3. Prioritization using the MoSCoW method (Must have, Should have, Could have, Won’t have) as recommended in agile software development[@srivastava2017scrum].

This synthesis process ensured that the final requirements specification incorporated both the functional and non-functional needs of diverse stakeholders, and that the resulting system design balanced technical feasibility with practical utility.


## Population and Sample

### Target Population
The target population for this study consisted of individuals and groups who would either directly use or influence the adoption of the proposed skin lesion detection and classification system. This included:

- **Health Professionals**: Dermatologists, general practitioners, and other medical personnel involved in skin disease diagnosis and treatment. Their expertise was vital in validating clinical accuracy requirements, determining acceptable error thresholds, and ensuring the system aligned with established diagnostic workflows [@hay2006skin; @esteva2017dermatologist].  
- **Technical Experts**: Machine learning researchers, computer vision engineers, and software developers with experience in healthcare applications. Their input guided architectural design choices, algorithm selection, and system integration strategies [@khan2021multi].  
- **Non-Technical Individuals**: Members of the general public, particularly those with limited access to dermatological services. This group provided insight into usability, accessibility, and trust factors, especially in contexts where teledermatology may serve as a first point of consultation [@zafar2023skin].

### Sampling Strategy
Given the diversity of the target population, a **stratified sampling approach** was adopted, dividing respondents into two broad strata:  

1. **Technical and Health Professionals** — selected using **purposive sampling**, ensuring that only individuals with relevant domain knowledge and professional experience were included. Recruitment was facilitated through professional associations, academic networks, and LinkedIn outreach.  
2. **Non-Technical Individuals** — selected using **convenience sampling**, leveraging community networks, social media outreach, and university mailing lists. This method was chosen for its practicality and efficiency in reaching a large pool of respondents in a limited timeframe.

This mixed approach ensured both the depth of expert feedback and the breadth of general user perspectives.

### Sample Size
A total of **25** responses were collected from technical and health professionals, and **50** responses from non-technical individuals. While the sample size for each group was constrained by resource availability and the duration of the requirement gathering phase, it was sufficient to capture recurring patterns and requirements for system design.

### Justification of Sample Size
In requirement elicitation for specialized healthcare AI systems, depth of insight is often more critical than sheer volume of responses [@ruparelia2010software]. For technical and health professionals, a smaller but highly relevant participant pool can yield actionable requirements without unnecessary redundancy. The non-technical sample size, while larger, was chosen to ensure diversity in age, education, and technology literacy, thereby reflecting the heterogeneity of potential end-users.

### Limitations of Sampling Approach
Despite its effectiveness, the sampling approach had limitations:

- **Selection Bias**: Purposive sampling may have excluded certain professional subgroups, particularly in rural or resource-limited regions.
- **Geographical Constraints**: The majority of respondents were located in urban centers, potentially under-representing rural healthcare contexts where teledermatology may have the highest impact.
- **Response Bias**: Online surveys can disproportionately attract participants with higher digital literacy, possibly skewing usability feedback.

These limitations are acknowledged and considered when interpreting the requirement gathering results and in the subsequent system design stages.

## Quantitative Analysis

### Data Analysis Techniques
Quantitative analysis was performed on the closed-ended questions from the surveys, focusing on numerical and categorical variables. The primary objective was to extract measurable trends regarding user expectations, clinical requirements, and perceived usability of the proposed skin lesion detection system.

Descriptive statistics, including **mean**, **median**, **mode**, and **standard deviation**, were calculated for ordinal and interval-scale responses. For nominal data, frequency distributions and percentages were computed. Cross-tabulation was employed to explore potential relationships between demographic variables (e.g., profession, years of experience, age group) and perceptions of the system [@hay2006skin; @ruparelia2010software].  

To ensure robustness, data analysis adhered to established guidelines for handling mixed healthcare and technology survey data [@khan2021multi]. Data cleaning included the removal of incomplete responses and the normalization of Likert-scale entries for comparability across questions.

### Data Visualization
Data visualization was used extensively to communicate quantitative findings clearly. Bar charts, pie charts, and stacked column graphs were employed to depict categorical distributions, while histograms illustrated the spread of numerical responses. For relationship analysis, clustered bar charts and side-by-side box plots were applied.

For example:

- Distribution of confidence levels in AI-assisted diagnosis among professionals versus non-technical users.
- Comparative importance ratings of system features such as **diagnosis speed**, **accuracy**, and **explainability**.
- Patterns in willingness to adopt the system across different age groups.

Visualizations were produced using spreadsheet software and statistical tools, ensuring clarity for both technical and non-technical audiences.

### Interpretation and Findings
Quantitative results revealed several key trends:

- **Accuracy Thresholds**: Health professionals consistently identified a minimum acceptable accuracy rate above 90% for clinical decision support, while non-technical users were more tolerant of slightly lower accuracy levels if accompanied by clear explanations [@esteva2017dermatologist].
- **Feature Prioritization**: Across both groups, the most highly rated features were real-time analysis, mobile accessibility, and privacy safeguards.
- **Adoption Willingness**: Willingness to adopt was highest among younger respondents and those with prior telemedicine experience, suggesting that digital familiarity positively influences acceptance.

These findings highlight the importance of tailoring the system’s feature set and communication style to different user categories.

### Conclusion
The quantitative analysis provided objective, measurable insights into user requirements and priorities. By quantifying trends and preferences, the results served as a foundation for setting design specifications, performance benchmarks, and usability targets. This ensured that subsequent system development steps were guided by evidence-based requirements rather than assumptions.

## Qualitative Analysis

### Thematic Analysis Approach
Qualitative analysis was conducted on the open-ended survey responses, interview transcripts, and focus group discussions. The primary objective was to identify recurring themes, contextual nuances, and stakeholder concerns that could not be captured through purely numerical measures.

A **thematic analysis** approach was adopted, following the steps outlined by Braun and Clarke [@braun2006using]\*:

  1. **Familiarization**: Repeated reading of the raw text data to immerse in the content and context.
  2. **Initial Coding**: Assigning descriptive labels to meaningful segments of text, capturing both explicit statements and implied sentiments.
  3. **Theme Development**: Grouping related codes into broader thematic categories.
  4. **Reviewing Themes**: Cross-checking against the dataset to ensure themes accurately represented the participants’ views.
  5. **Defining and Naming Themes**: Refining theme descriptions for clarity and relevance.
  6. **Reporting**: Selecting illustrative quotes to convey the essence of each theme.

### Coding and Categorization
Responses were coded manually using spreadsheet-based coding tables. This process produced multiple overarching categories:
- **Accuracy and Trust**: Emphasis on clinical reliability and the need for human oversight in diagnosis [@esteva2017dermatologist; @zafar2023skin].
- **Usability and Accessibility**: Concerns over interface simplicity, language localization, and mobile optimization for low-bandwidth environments.
- **Privacy and Ethics**: Demand for strict compliance with data protection regulations and transparent data usage policies [@khan2021multi].
- **Educational Value**: Interest in integrating explanations and visual aids to help users understand lesion classifications and potential risks.

### Interpretation of Qualitative Findings
The qualitative data revealed several insights that influenced design decisions:

- **Differing Risk Tolerance**: Medical professionals prioritized minimizing false negatives, even at the cost of slightly lower overall accuracy, whereas non-technical users valued a balance between speed and reliability.
- **Need for Explainability**: Across all groups, participants favored outputs accompanied by visual indicators and textual explanations, supporting findings in explainable AI literature.
- **Cultural and Language Considerations**: Participants from non-English-speaking backgrounds stressed the importance of multilingual support for both the interface and educational materials.

These findings underscored the necessity of designing a system that is not only technically sound but also socially and ethically acceptable.

### Conclusion
By capturing and analyzing the rich detail of participants’ perspectives, the qualitative analysis complemented the quantitative results, providing a holistic understanding of user and stakeholder needs. The combination of both methods ensured that the system’s design was informed by statistically significant trends as well as the subtler, contextual factors that can impact adoption and trust.


## Dataset Description and Preprocessing

The dataset used in this study was curated from multiple open-source dermatological image repositories and validated clinical sources. It comprises high-quality images covering **33 unique skin condition categories**, spanning viral, bacterial, fungal, parasitic, autoimmune, inflammatory, and neoplastic conditions. Unlike conventional dermatological datasets such as **HAM10000**, which focus predominantly on melanocytic lesions [@khan2021multi; @tschandl2018ham10000], this dataset extends coverage to a broader spectrum of dermatological manifestations, enabling a more versatile diagnostic tool.

### Dataset Composition

The dataset categories are as follows:

- **Viral Infections:** Chickenpox, Monkeypox, Measles, Shingles, Herpes, Cowpox.
- **Bacterial Infections:** Impetigo, Leprosy, Whitlow.
- **Fungal Infections:** Athlete’s Foot, Ringworm, Nail Fungus.
- **Parasitic Infestations:** Scabies, Tungiasis, Larva Migrans.
- **Inflammatory and Autoimmune Conditions:** Eczema, Psoriasis, Autoimmune Disease, Rash Dermatitis, Vitiligo.
- **Benign and Malignant Tumors:** Basal Cell Carcinoma (BCC), Squamous Cell Carcinoma (SCC), Actinic Keratosis, Melanoma, Nevus, Seborrheic Keratosis, Benign Tumor, Moles.
- **Other Dermatological Conditions:** Acne, Neurofibromatosis, Vascular Lesion, Healthy skin.

This broad coverage is particularly valuable for **primary care and teledermatology**, where non-specialist practitioners encounter diverse skin pathologies [@zafar2023skin; @adegun2020fcn].


### Data Sources

The dataset was compiled from:

- **Public dermatology datasets** — e.g., HAM10000, ISIC Archive (for melanoma, nevus, keratosis, and carcinoma images).
- **Open-access image repositories** — curated collections for conditions such as chickenpox, monkeypox, and scabies.
- **Institutional contributions** — small-scale, ethically approved clinical image sets for rare conditions such as tungiasis and larva migrans.

All images were reviewed to ensure:

- Minimum resolution of 224×224 pixels before resizing.
- Clear lesion visibility with minimal occlusions.
- Correct disease labeling by source datasets.


### Dataset Distribution and Class Imbalance

The dataset is **imbalanced**:  
Classes like *Acne* and *Eczema* have large sample counts, while rare conditions such as *Tungiasis* or *Larva Migrans* have far fewer. Such imbalance can bias models toward majority classes, leading to reduced recall for rare categories [@buda2018systematic; @kassem2021machine].

Mitigation strategies applied:

- **Class weighting** — Computed via `sklearn.utils.class_weight` and incorporated into the cross-entropy loss.
- **Data augmentation** — Uniformly applied at runtime, with possible further targeted augmentation for minority classes in future iterations.

<!-- @todo 
**[Placeholder: Table — Number of images per class for train, validation, and test sets]**  
**[Placeholder: Figure — Class distribution plot across splits]**
-->


### 3.3.4 Data Partitioning

Images were split into:

- **Training set:** 70%
- **Validation set:** 15%
- **Test set:** 15%

Splitting was **stratified per class** to preserve class proportions across sets, ensuring fair evaluation.


### Exploratory Data Analysis (EDA)

Before training, **EDA** was conducted on the processed dataset to assess its suitability:

1. **Class distribution analysis** — Generated bar plots to visualize image counts per class for each dataset split, confirming imbalance patterns.
2. **Sample inspection** — Random samples per class were displayed to verify label correctness and assess intra-class variability.
3. **Image dimension profiling** — Recorded resolutions and aspect ratios from random subsets to guide resizing and padding strategies.

<!-- @todo **[Placeholder: Figure — Example sample images per class]** -->


### Preprocessing Pipeline

A reproducible preprocessing pipeline was implemented in Python, combining **offline standardization** and **online augmentation**:

#### Offline Processing

- **Image Conversion** — Ensured all images were in RGB mode to match the pretrained ResNet input format.
- **Resizing with Padding** — Used **Lanczos resampling** to resize while preserving aspect ratio, padding with a neutral grey background (128, 128, 128) to reach 224×224 pixels.
- **Format Standardization** — Saved all outputs as high-quality JPEG files for consistency.
- **Directory Structuring** — Images organized into `train`, `val`, and `test` directories by class.

#### Online Augmentation (During Training)

| Transformation | Purpose | Parameters |
|----------------|----------------------------------|----------------------------------|
| Random Horizontal Flip | Simulate left/right lesion orientation | p = 0.5 |
| Random Rotation | Account for patient positioning differences | ±10° |
| Color Jitter | Simulate lighting variations | brightness=0.2, contrast=0.2, saturation=0.2 |
| Normalization | Match ImageNet statistics | mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] |

These augmentations improve generalization and reduce overfitting [@lecun2015deep; @mahbod2019skin].

<!-- @todo **[Placeholder: Figure — Raw vs. preprocessed image examples]** -->


### Impact of Preprocessing and Augmentation

The chosen preprocessing and augmentation steps:

- Improved robustness to variations in lighting, camera quality, and orientation.
- Reduced the risk of overfitting by diversifying the training data.
- Preserved lesion geometry, which is essential for dermatology-specific feature learning.

## Model Architecture

The classification model is based on a **fine-tuned ResNet-18** [@he2016deep], selected for its favorable trade-off between accuracy and computational cost. This architecture is well-suited for mobile and edge deployment due to its small parameter count and competitive accuracy in medical image tasks [@esteva2017dermatologist].


### Baseline Architecture

ResNet-18 comprises:

- An initial convolutional layer (7×7 kernel, stride 2) followed by batch normalization and ReLU activation.
- Four sequential residual blocks (layers 1–4) with skip connections to facilitate gradient flow.
- Global average pooling, followed by a fully connected (fc) layer for classification.


### Transfer Learning Adaptations

To adapt ResNet-18 for multi-class lesion classification:

- **Weights** initialized from ImageNet-pretrained ResNet-18 (`ResNet18_Weights.DEFAULT`).
- **Frozen layers:** Layers 1–3 kept frozen to retain generic visual features.
- **Unfrozen layers:** Layer 4 and the fc layer trained for dermatology-specific adaptation.
- **Modified final layer:** Replaced `fc` with `nn.Linear(512, 33)` for 33-class output.

This selective fine-tuning strategy combines pretrained low- and mid-level feature extraction with high-level feature specialization [@yosinski2014transfer].


### Loss Function and Class Balancing

A **weighted cross-entropy loss** was employed, where each class weight was inversely proportional to its frequency in the training set. This approach ensured that minority classes contributed more to gradient updates, improving detection rates for rare conditions.


### Optimization and Regularization

Training configuration:

- **Optimizer:** Adam (`lr=0.001`, `weight_decay=1e-4`).
- **Scheduler:** ReduceLROnPlateau (factor=0.5, patience=2).
- **Early Stopping:** Stop if validation loss fails to improve for 5 epochs.
- **Batch Size:** 32.

Regularization via L2 weight decay and early stopping reduced overfitting, while dynamic learning rate adjustment improved convergence stability.


### Rationale for ResNet-18 Selection

ResNet-18 was chosen because:

1. It delivers high accuracy with relatively low inference time.
2. Prior studies confirm ResNet’s effectiveness for skin lesion classification [@albahar2019skin; @harangi2018skin].
3. Its moderate depth supports deployment on resource-constrained devices without heavy hardware requirements.

<!-- @todo **[Placeholder: Diagram — Modified ResNet-18 highlighting unfrozen layers and custom classification head]**-->


## Training Strategy

The training phase was carefully designed to achieve a balance between **computational efficiency**, **classification accuracy**, and **generalization capability** to unseen images. This section describes the training configuration, rationale for hyperparameter selection, and mechanisms adopted to handle the inherent challenges of medical image classification.

### Hardware and Frameworks

All model training was conducted on a GPU-enabled workstation equipped with CUDA support. This significantly reduced training time compared to CPU-based execution, enabling faster experimentation and hyperparameter tuning. The model was implemented in **PyTorch**, chosen for its flexibility and strong community support in research-oriented deep learning tasks. Supporting libraries included:

- **torchvision** for pretrained model loading and image transformation pipelines.
- **scikit-learn** for computing class weights and auxiliary evaluation metrics.
- **tqdm** for real-time progress tracking.
- **TensorBoard** for monitoring loss, accuracy, and learning rate trends over epochs.

### Data Loading and Batching

The processed dataset (Section 3.3) was loaded via PyTorch’s `DataLoader` class with the following configurations:

- **Batch Size:** 32 images per iteration — a compromise between computational efficiency and GPU memory constraints.
- **Shuffling:** Enabled for the training set to ensure diverse sample exposure per batch, breaking any inherent ordering in the data.
- **Parallelism:** Four worker threads (`num_workers=4`) with a prefetch factor of four, minimizing idle GPU time due to data loading delays.

This setup ensured that each training iteration received a randomized, memory-optimized batch, which has been shown to improve convergence rates [@goodfellow2016deep].

### Transfer Learning and Layer Freezing

Given the limited availability of dermatological images for certain rare conditions, training a deep convolutional neural network from scratch was deemed impractical. Instead, **transfer learning** was employed using a ResNet-18 architecture pretrained on the ImageNet dataset. The transfer learning strategy included:

- **Freezing layers 1–3:** Preserving generic feature extractors (edges, textures, shapes) learned from the large-scale ImageNet dataset.
- **Unfreezing layer 4 and the fully connected layer:** Allowing adaptation of higher-level feature representations to the unique textures and lesion patterns in dermatological images.
- **Classifier replacement:** Modifying the final fully connected layer to output 33 logits corresponding to the target disease categories.

Selective unfreezing reduced the risk of overfitting while allowing enough flexibility for domain adaptation [@yap2018multimodal].

### Loss Function and Class Balancing

A major challenge identified during exploratory data analysis (EDA) was **class imbalance**, with conditions like *Eczema* and *Acne* having significantly more samples than rare diseases such as *Tungiasis* or *Cowpox*. Without correction, the model would bias predictions toward majority classes. To address this:

- **Weighted Cross-Entropy Loss** was used, with per-class weights computed using:

\[
w_c = \frac{N}{n_c \cdot K}
\]

where:

- \(N\) is the total number of training samples,
- \(n_c\) is the sample count for class \(c\),
- \(K\) is the number of classes.

These weights were passed directly to PyTorch’s `nn.CrossEntropyLoss`, ensuring that errors on minority classes contributed proportionally more to gradient updates. This method is well-supported in medical imaging literature for combating imbalance [@krawczyk2016learning].

### Optimization and Learning Rate Scheduling

Optimization was handled by the **Adam** optimizer with:

- Learning rate \( \alpha = 0.001 \),
- Weight decay \( = 1\times 10^{-4} \) for L2 regularization.

Adam was chosen for its adaptive learning rates and robustness to sparse gradients [@adam2014method]. To avoid stagnation, the `ReduceLROnPlateau` scheduler was employed, reducing the learning rate by a factor of 0.5 if validation loss failed to improve for two consecutive epochs.

### Early Stopping

To prevent overfitting and unnecessary computation, **early stopping** was implemented with a patience of 5 epochs, if no improvement in validation loss was observed during this period, training terminated. This approach aligns with best practices in deep learning model regularization [@prechelt1998early].

### Epochs, Monitoring, and Logging

The model was trained for a maximum of **20 epochs**. Real-time metrics were logged to TensorBoard, capturing:

- Training and validation loss curves,
- Training and validation accuracy curves,
- Learning rate schedules.

<!-- @todo
**[Placeholder: Figure — Training and validation loss curves]**  
**[Placeholder: Figure — Training and validation accuracy curves]**
--->

## Evaluation Strategy

The evaluation methodology was designed to quantify not only the **overall classification performance** but also the **per-class diagnostic reliability**, given the medical context of the task.

### Test Set Protocol

All reported results are based on the **test set**, which was strictly isolated from training and validation data to ensure unbiased performance estimates. This set simulates real-world deployment conditions by containing images unseen by the model at any training stage.

### Evaluation Metrics

Given the dataset imbalance and the multi-class nature of the problem, we employed the following metrics:

- **Accuracy:**
\[
\text{Accuracy} = \frac{\text{Number of correct predictions}}{\text{Total number of predictions}}
\]

While intuitive, accuracy alone may mask poor minority-class performance in imbalanced datasets.

- **Precision (per class and macro-averaged):**
\[
\text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
\]

Precision is critical in medical applications where false positives can lead to unnecessary anxiety or treatment.

- **Recall / Sensitivity:**
\[
\text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
\]

High recall ensures that most true cases are detected, reducing missed diagnoses.

- **F1-Score:**
\[
\text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\]

Balances the trade-off between precision and recall.

- **Confusion Matrix:**

Visualizes per-class prediction performance and highlights common misclassifications (e.g., *Seborrheic Keratosis* misclassified as *Actinic Keratosis*).

- **ROC AUC (One-vs-Rest):**
Measures separability between each class and all others, providing insight into decision threshold robustness.

<!-- @todo
**[Placeholder: Table — Overall accuracy, macro/micro precision, recall, and F1-score]**  
**[Placeholder: Figure — Confusion matrix heatmap]**  
**[Placeholder: Figure — ROC curves per class]**
-->

### Rationale for Metric Selection

These metrics were selected based on clinical relevance. In dermatology AI, high recall is often prioritized to minimize missed malignant cases, while high precision reduces unnecessary biopsies or referrals. Macro-averaging ensures all classes contribute equally to the overall performance measure, regardless of prevalence.

### Additional Performance Considerations

Given the intended integration into a **CLI** for research and a **React Native** mobile application, additional evaluations were made on:

- **Inference latency** — to ensure acceptable response times on standard mobile hardware.
- **Model size and memory footprint** — to confirm feasibility for mobile and edge deployment.

### Visualizations

Performance visualizations will be added to the final report:

- Loss and accuracy curves across epochs,
- Confusion matrix heatmap for error analysis,
- ROC curves for multi-class separability assessment.

These plots aid in communicating results to both technical and clinical audiences.

## System Deployment

The deployment phase transforms the trained skin lesion classification model into a functional application ecosystem that is accessible to both researchers and end-users. This involves integrating the AI model into multiple delivery channels, a **command-line interface (CLI)** for advanced research workflows, and a **React Native mobile application** for primary care and public health use. Deployment considerations also include hosting infrastructure, scalability, data privacy, and regulatory compliance.


### Deployment Objectives

The system deployment aims to:

1. **Ensure accessibility** — enable both technical and non-technical users to interact with the model.
2. **Maintain efficiency** — achieve low-latency inference, even on resource-constrained devices.
3. **Support scalability** — allow expansion to larger datasets, additional disease classes, and multi-language support.
4. **Facilitate integration** — ensure the model can be embedded into broader healthcare systems or telemedicine platforms.


### Command-Line Interface (CLI) for Researchers

The CLI is designed to serve dermatology researchers and data scientists who require batch processing, model experimentation, and in-depth performance analytics.

#### Key Features:

- **Single-image and batch prediction modes**  
  Researchers can run predictions on individual lesion images or entire folders.
- **Output formats**  
  Predictions can be saved in CSV/JSON format, containing the predicted class, confidence scores, and timestamp.
- **Model evaluation tools**  
  Researchers can compute metrics such as accuracy, precision, recall, F1-score, and generate confusion matrices on new datasets.
- **Custom model loading**  
  Allows researchers to test alternative trained models by specifying the path via a command-line argument.

<!-- @todo 
**[Placeholder: Screenshot of CLI prediction output]**
--->

### Mobile Application for End-Users

The React Native mobile application is intended for healthcare practitioners, field workers, and potentially patients for preliminary lesion screening.  
The app will integrate the trained ResNet-18 model either **on-device** (for offline capability) or via **cloud-hosted inference APIs** (for lighter device workloads).

#### Core Features:

- **Image Capture & Upload**  
  Users can capture lesion images directly via the phone’s camera or upload from the gallery.
- **Instant Classification**  
  The app provides top predictions with confidence scores.
- **Educational Content**  
  Displays information about predicted conditions, including symptoms and recommended next steps.
- **Offline Mode (Planned)**  
  A lightweight, quantized version of the model can be embedded for use in low-connectivity regions.

<!--
**[Placeholder: Mobile UI mockup showing classification screen]**
--->

### Hosting and API Infrastructure

The hosting approach will depend on the final budget and resource allocation. Two main configurations are under consideration:

1. **Serverless Cloud Deployment** *(initial preference)*

   - Utilizes platforms like AWS Lambda or Google Cloud Functions.  
   - Advantages: automatic scaling, pay-per-use billing, minimal server maintenance.  
   - Disadvantage: AWS credit expiry may require migration.

2. **Dedicated Cloud Server / Containerized Deployment** *(alternative plan)* 

   - Hosted on services like AWS EC2, DigitalOcean, or Azure VMs.  
   - Docker containers for consistent deployment environments.  
   - Potential GPU-enabled instances for faster inference.


<!--
**[Placeholder: System architecture diagram — mobile app, API gateway, model inference, database, user interface]**
--->

### Deployment Workflow

The deployment workflow includes:

1. **Model Export** — trained model saved in `.pth` and `.pt` formats for compatibility with both PyTorch and TorchScript (mobile deployment).
2. **API Development** — RESTful API endpoints for:

   - `/predict` — accept image input, return classification results.
   - `/health` — server health check.
   - `/version` — current model version.

3. **Integration Testing** — ensuring consistent predictions across CLI, mobile, and API-based requests.
4. **Security and Privacy** — enforce HTTPS for data transfer, anonymize image metadata, and comply with GDPR/HIPAA standards where applicable.


### Monitoring and Maintenance

Post-deployment, the system will include:

- **Usage analytics** — monitor API requests, app downloads, and prediction frequency.
- **Model performance tracking** — periodic testing with new data to detect performance drift.
- **Continuous improvement cycle** — retraining with new cases, including rare or misclassified conditions.

<!--
**[Placeholder: Deployment timeline Gantt chart — from model export to production launch]**
-->

## Summary of Methodology

This chapter presented the complete methodology adopted for the design, development, training, and deployment of the proposed **skin lesion detection and classification system**. The approach was guided by the **CRISP-DM** framework, ensuring that every stage, from problem definition to system deployment, followed a structured, iterative, and evidence-driven process.

The **business understanding phase** established the project’s core objective: to develop a multi-condition dermatological diagnostic aid that can assist healthcare practitioners and researchers by classifying a wide range of skin lesions. Unlike many prior works such as those based on the HAM10000 dataset, which focus primarily on melanoma and a few related conditions, our system targets **33 unique dermatological conditions** spanning viral, bacterial, fungal, parasitic, autoimmune, inflammatory, and neoplastic categories. This broad coverage is intended to make the system more relevant in **primary care, rural healthcare, and teledermatology contexts**, where clinicians may encounter a diverse set of skin disorders.

The **data understanding phase** involved collecting images from multiple open-source dermatology datasets, open-access medical repositories, and selected institutional sources. Exploratory Data Analysis (EDA) was conducted to assess the dataset’s structure, identify imbalances, and verify image quality. The EDA included:

- **Class distribution analysis**, revealing significant imbalances (e.g., Acne and Eczema having hundreds of samples, while Tungiasis and Cowpox had far fewer).
- **Image dimension inspection**, confirming varied resolutions before preprocessing.
- **Visual inspection of samples** to validate labeling accuracy and ensure lesion visibility.

The **data preparation phase** applied a comprehensive preprocessing pipeline tailored to dermatology-specific needs. Images were resized to **224×224 pixels** with padding to preserve aspect ratios, converted to RGB, and normalized to match ImageNet statistics (mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]). Data augmentation techniques including random horizontal flips, small rotations (±10°), and color jitter were used to simulate variations in orientation, lighting, and camera quality, thereby improving model robustness. Class imbalance was addressed by calculating **class weights** from the training set and applying them in the loss function, ensuring rare conditions were not overshadowed by more common ones.

The **modeling phase** implemented a **fine-tuned ResNet-18 architecture** initialized with pretrained weights from ImageNet. Only the final residual block (layer4) and the fully connected classification layer were unfrozen to adapt high-level features to dermatological patterns, while earlier layers retained their pretrained weights to preserve general feature extraction capability. The model was trained with:

- **Loss function** — weighted cross-entropy.
- **Optimizer** — Adam (lr=0.001, weight_decay=1e-4) to balance learning speed and regularization.
- **Scheduler** — ReduceLROnPlateau to adjust the learning rate when validation loss plateaued.
- **Early stopping** — halting training after 5 epochs without improvement to prevent overfitting.
- **Batch size** — 32, selected to balance memory constraints and gradient stability.

Performance metrics during training and evaluation included **accuracy, precision, recall, and F1-score**. Additional metrics, **confusion matrix, per-class precision/recall, and ROC curves**, are planned for inclusion in the results chapter to provide a more granular performance breakdown.

The **evaluation phase** ensured unbiased testing by maintaining a strict 70/15/15 train/validation/test split. The model that achieved the best validation loss was saved in both `.pth` (PyTorch format) and `.pt` (TorchScript format) for compatibility with different deployment targets.

The **deployment phase** envisioned a two-pronged delivery approach:

1. **Command-Line Interface (CLI)** — Designed purely for inference, enabling researchers to run single-image or batch predictions and receive results in CSV/JSON formats, complete with predicted class and confidence scores.
2. **React Native Mobile Application** — Intended for healthcare practitioners and general users. The final deployment will utilize a **cloud-hosted API** for inference to keep the mobile application lightweight, avoid excessive on-device computation, and enable easier model updates without requiring app reinstallation.

Hosting considerations focused on **cloud-based API deployment**, with the initial preference being **serverless infrastructure** (e.g., AWS Lambda) for cost efficiency and automatic scaling. A containerized alternative (e.g., Docker on AWS EC2 or DigitalOcean) is reserved as a fallback option, particularly after the expiration of AWS credits. The deployment architecture will initially include only the currently planned components, mobile app, API gateway, model inference service, and a minimal database for request logging, with no hospital EMR integration at this stage.

Throughout this methodology, careful attention was paid to both **technical performance** and **practical usability**. The CRISP-DM framework provided the flexibility to refine earlier stages based on insights from later phases, for example, adjusting augmentation strategies in response to observed overfitting during model training. By combining robust deep learning techniques with a deployment design mindful of user needs and infrastructure realities, the system is positioned to deliver both **research-grade accuracy** and **field-ready accessibility**.

The next chapter, **Results and Discussion**, will present the outcomes of this methodology, including quantitative performance metrics, visualizations of training dynamics, and an analysis of strengths and limitations relative to existing solutions.



\newpage

# Chapter 4: System Design and Implementation

* 4.1 System Overview
* 4.2 Functional Requirements
* 4.3 System Architecture Diagram
* 4.4 Data Flow and Pipeline
* 4.5 CLI and GUI Components
* 4.6 Integration and Deployment
* 4.7 Inference and Prediction Logic
* 4.8 Summary

\newpage

# Chapter 5: Testing, Results, and Discussion

* 5.1 Dataset Splits (Train, Validation, Test)
* 5.2 Accuracy, Loss, and Confusion Matrix
* 5.3 ROC, Precision, Recall, F1-score
* 5.4 Model Limitations and Observed Bias
* 5.5 Comparison with Existing Systems
* 5.6 Summary

\newpage

# Chapter 6: Conclusion and Recommendations

* 6.1 Summary of Findings
* 6.2 Conclusion
* 6.3 Contributions of the Study
* 6.4 Recommendations for Future Work
* 6.5 Final Remarks

\newpage

# Appendices

* Appendix A: Source Code Snippets
* Appendix B: Model Configurations
* Appendix C: Training Graphs
* Appendix D: Screenshots of GUI
* Appendix E: User Manual

\newpage

# References


